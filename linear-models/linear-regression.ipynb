{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MyLineReg:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_iter: int = 100,\n",
    "        learning_rate: float = 0.1,\n",
    "        W: np.array = None,\n",
    "        metric: str = None,\n",
    "        reg: str = None,\n",
    "        l1_coef: float = 0.0,\n",
    "        l2_coef: float = 0.0,\n",
    "        sgd_sample = None,\n",
    "        random_state: int = 42\n",
    "    ):\n",
    "        self.n_iter = n_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.W = None\n",
    "        self.metric = metric\n",
    "        self.score = 0\n",
    "        self.reg = reg\n",
    "        self.l1_coef = l1_coef\n",
    "        self.l2_coef = l2_coef\n",
    "        self.sgd_sample = sgd_sample\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def mse(y_true, y_pred):\n",
    "        return np.mean((y_true - y_pred)**2)\n",
    "        \n",
    "    def mae(y_true, y_pred):\n",
    "        return np.mean(np.abs(y_true - y_pred))\n",
    "        \n",
    "    def rmse(y_true, y_pred):\n",
    "        return np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "        \n",
    "    def mape(y_true, y_pred):\n",
    "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "        \n",
    "    def r2(y_true, y_pred):\n",
    "        SS_res = np.sum((y_true - y_pred)**2)\n",
    "        SS_tot = np.sum((y_true - np.mean(y_true))**2)\n",
    "        return 1 - (SS_res / SS_tot)\n",
    "    \n",
    "    metrics = {\"mse\": mse, \"mae\": mae, \"rmse\": rmse, \"mape\": mape, \"r2\": r2}\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X: pd.DataFrame,\n",
    "        y: pd.Series,\n",
    "        verbose: int = False\n",
    "    ) -> None:\n",
    "        random.seed(self.random_state)\n",
    "        X = pd.concat([pd.Series(1, index=X.index, name='bias'), X], axis=1)\n",
    "        n = X.shape[1]\n",
    "        self.W = np.ones(n)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"start | loss:\",  self.metrics[self.metric](y, np.dot(X, self.W)))\n",
    "        \n",
    "        for i in range(self.n_iter):\n",
    "            if self.sgd_sample is not None:\n",
    "                sample_size = int(self.sgd_sample * X.shape[0]) if isinstance(self.sgd_sample, float) else self.sgd_sample\n",
    "                sample_rows_idx = random.sample(range(X.shape[0]), sample_size)\n",
    "                X_batch = X.iloc[sample_rows_idx]\n",
    "                y_batch = y.iloc[sample_rows_idx]\n",
    "            else:\n",
    "                X_batch = X\n",
    "                y_batch = y\n",
    "\n",
    "            y_pred = np.dot(X_batch, self.W)\n",
    "            loss = np.mean((y_batch - y_pred)**2)\n",
    "            gradient = 2 * X_batch.T @ (y_pred - y_batch) / len(y_batch)\n",
    "            \n",
    "            if self.reg == 'l1':\n",
    "                gradient += self.l1_coef * np.sign(self.W)\n",
    "            elif self.reg == 'l2':\n",
    "                gradient += 2 * self.l2_coef * self.W\n",
    "            elif self.reg == 'elasticnet':\n",
    "                gradient += self.l1_coef * np.sign(self.W) + 2 * self.l2_coef * self.W\n",
    "            \n",
    "            if callable(self.learning_rate):\n",
    "                lr = self.learning_rate(i+1)\n",
    "            else:\n",
    "                lr = self.learning_rate\n",
    "\n",
    "            self.W -= lr * gradient\n",
    "\n",
    "            if verbose and (i + 1) % verbose == 0 and self.metric:\n",
    "                print(f\"{i + 1} | loss: {loss} | {self.metric}: {metric_value}\")\n",
    "        \n",
    "        if self.metric:\n",
    "            metric_value = self.metrics[self.metric](y, np.dot(X, self.W))\n",
    "            self.score = metric_value\n",
    "\n",
    "    def get_coef(self):\n",
    "        return self.W[1:]\n",
    "    \n",
    "    def predict(self, X: pd.DataFrame):\n",
    "        X = pd.concat([pd.Series(1, index=X.index, name='bias'), X], axis=1)\n",
    "        y_pred = X @ self.W\n",
    "        return y_pred\n",
    "    \n",
    "    def get_best_score(self):\n",
    "        return self.score\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
